{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5438864f",
   "metadata": {},
   "source": [
    "# From Raw Text to Training Samples\n",
    "\n",
    "This notebook implements the data preparation pipeline required to train a Large Language Model (LLM), following Chapter 2 of *Build a Large Language Model (From Scratch)*.\n",
    "\n",
    "We focus on transforming raw text into structured training data suitable for next-token prediction.\n",
    "\n",
    "Specifically, we will:\n",
    "\n",
    "- Tokenize text using Byte Pair Encoding (BPE)\n",
    "- Convert tokens into token IDs\n",
    "- Generate input-target pairs using a sliding window\n",
    "- Build a PyTorch Dataset\n",
    "- Analyze how window parameters affect training data\n",
    "\n",
    "The objective is not only to implement the pipeline, but to understand how embeddings and sampling strategies shape the learning dynamics of LLMs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04ee1bd",
   "metadata": {},
   "source": [
    "## 1. Loading the Dataset\n",
    "\n",
    "We begin by loading the text file that will be used as training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc443881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in .\\.venv\\Lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: tiktoken in .\\.venv\\Lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: jupyter in .\\.venv\\Lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: filelock in .\\.venv\\Lib\\site-packages (from torch) (3.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in .\\.venv\\Lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in .\\.venv\\Lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in .\\.venv\\Lib\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in .\\.venv\\Lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in .\\.venv\\Lib\\site-packages (from torch) (2026.2.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in .\\.venv\\Lib\\site-packages (from tiktoken) (2026.2.19)\n",
      "Requirement already satisfied: requests>=2.26.0 in .\\.venv\\Lib\\site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: notebook in .\\.venv\\Lib\\site-packages (from jupyter) (7.5.3)\n",
      "Requirement already satisfied: jupyter-console in .\\.venv\\Lib\\site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in .\\.venv\\Lib\\site-packages (from jupyter) (7.17.0)\n",
      "Requirement already satisfied: ipykernel in .\\.venv\\Lib\\site-packages (from jupyter) (7.2.0)\n",
      "Requirement already satisfied: ipywidgets in .\\.venv\\Lib\\site-packages (from jupyter) (8.1.8)\n",
      "Requirement already satisfied: jupyterlab in .\\.venv\\Lib\\site-packages (from jupyter) (4.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in .\\.venv\\Lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\.venv\\Lib\\site-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.venv\\Lib\\site-packages (from requests>=2.26.0->tiktoken) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\.venv\\Lib\\site-packages (from requests>=2.26.0->tiktoken) (2026.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in .\\.venv\\Lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in .\\.venv\\Lib\\site-packages (from ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in .\\.venv\\Lib\\site-packages (from ipykernel->jupyter) (1.8.20)\n",
      "Requirement already satisfied: ipython>=7.23.1 in .\\.venv\\Lib\\site-packages (from ipykernel->jupyter) (9.10.0)\n",
      "Requirement already satisfied: jupyter-client>=8.8.0 in .\\.venv\\Lib\\site-packages (from ipykernel->jupyter) (8.8.0)\n",
      "Requirement already satisfied: jupyter-core!=6.0.*,>=5.1 in .\\.venv\\Lib\\site-packages (from ipykernel->jupyter) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in .\\.venv\\Lib\\site-packages (from ipykernel->jupyter) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in .\\.venv\\Lib\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging>=22 in .\\.venv\\Lib\\site-packages (from ipykernel->jupyter) (26.0)\n",
      "Requirement already satisfied: psutil>=5.7 in .\\.venv\\Lib\\site-packages (from ipykernel->jupyter) (7.2.2)\n",
      "Requirement already satisfied: pyzmq>=25 in .\\.venv\\Lib\\site-packages (from ipykernel->jupyter) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.4.1 in .\\.venv\\Lib\\site-packages (from ipykernel->jupyter) (6.5.4)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in .\\.venv\\Lib\\site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Requirement already satisfied: colorama>=0.4.4 in .\\.venv\\Lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.4.6)\n",
      "Requirement already satisfied: decorator>=4.3.2 in .\\.venv\\Lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in .\\.venv\\Lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in .\\.venv\\Lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in .\\.venv\\Lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in .\\.venv\\Lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in .\\.venv\\Lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in .\\.venv\\Lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->jupyter) (0.6.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in .\\.venv\\Lib\\site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel->jupyter) (0.8.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in .\\.venv\\Lib\\site-packages (from jupyter-client>=8.8.0->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in .\\.venv\\Lib\\site-packages (from jupyter-core!=6.0.*,>=5.1->ipykernel->jupyter) (4.9.2)\n",
      "Requirement already satisfied: six>=1.5 in .\\.venv\\Lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.8.0->ipykernel->jupyter) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in .\\.venv\\Lib\\site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel->jupyter) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in .\\.venv\\Lib\\site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel->jupyter) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in .\\.venv\\Lib\\site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in .\\.venv\\Lib\\site-packages (from ipywidgets->jupyter) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in .\\.venv\\Lib\\site-packages (from ipywidgets->jupyter) (3.0.16)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in .\\.venv\\Lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in .\\.venv\\Lib\\site-packages (from jupyterlab->jupyter) (2.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in .\\.venv\\Lib\\site-packages (from jupyterlab->jupyter) (0.28.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in .\\.venv\\Lib\\site-packages (from jupyterlab->jupyter) (2.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in .\\.venv\\Lib\\site-packages (from jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.28.0 in .\\.venv\\Lib\\site-packages (from jupyterlab->jupyter) (2.28.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in .\\.venv\\Lib\\site-packages (from jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in .\\.venv\\Lib\\site-packages (from jupyterlab->jupyter) (65.5.0)\n",
      "Requirement already satisfied: anyio in .\\.venv\\Lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in .\\.venv\\Lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in .\\.venv\\Lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter) (0.16.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in .\\.venv\\Lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in .\\.venv\\Lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in .\\.venv\\Lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.4)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in .\\.venv\\Lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in .\\.venv\\Lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in .\\.venv\\Lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.24.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in .\\.venv\\Lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.3)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in .\\.venv\\Lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.1.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in .\\.venv\\Lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in .\\.venv\\Lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.9.0)\n",
      "Requirement already satisfied: babel>=2.10 in .\\.venv\\Lib\\site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (2.18.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in .\\.venv\\Lib\\site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (0.13.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in .\\.venv\\Lib\\site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (4.26.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in .\\.venv\\Lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in .\\.venv\\Lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in .\\.venv\\Lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in .\\.venv\\Lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in .\\.venv\\Lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (0.30.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in .\\.venv\\Lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (4.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in .\\.venv\\Lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.3)\n",
      "Requirement already satisfied: rfc3339-validator in .\\.venv\\Lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in .\\.venv\\Lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: fqdn in .\\.venv\\Lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in .\\.venv\\Lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in .\\.venv\\Lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in .\\.venv\\Lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.1.0)\n",
      "Requirement already satisfied: uri-template in .\\.venv\\Lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in .\\.venv\\Lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.10.0)\n",
      "Requirement already satisfied: beautifulsoup4 in .\\.venv\\Lib\\site-packages (from nbconvert->jupyter) (4.14.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in .\\.venv\\Lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.3.0)\n",
      "Requirement already satisfied: defusedxml in .\\.venv\\Lib\\site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in .\\.venv\\Lib\\site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in .\\.venv\\Lib\\site-packages (from nbconvert->jupyter) (3.2.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in .\\.venv\\Lib\\site-packages (from nbconvert->jupyter) (0.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in .\\.venv\\Lib\\site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: webencodings in .\\.venv\\Lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in .\\.venv\\Lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in .\\.venv\\Lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.21.2)\n",
      "Requirement already satisfied: lark>=1.2.2 in .\\.venv\\Lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in .\\.venv\\Lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.0.0)\n",
      "Requirement already satisfied: pycparser in .\\.venv\\Lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in .\\.venv\\Lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (2.8.3)\n",
      "Requirement already satisfied: arrow>=0.15.0 in .\\.venv\\Lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.4.0)\n",
      "Requirement already satisfied: tzdata in .\\.venv\\Lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2025.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in .\\.venv\\Lib\\site-packages (2.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries (run this once if needed)\n",
    "%pip install torch tiktoken jupyter\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d7c392c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(\"Total characters:\", len(raw_text))\n",
    "print(raw_text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9645d124",
   "metadata": {},
   "source": [
    "## Why text preprocessing matters for LLMs\n",
    "\n",
    "Large Language Models cannot process raw text directly. Neural networks operate on numerical tensors, not strings. Therefore, before training an LLM, we must transform text into a numerical representation.\n",
    "\n",
    "This preprocessing stage defines:\n",
    "\n",
    "- The vocabulary\n",
    "- How context is represented\n",
    "- How meaning is captured\n",
    "\n",
    "If tokenization is poor, the model learns poor patterns. Good preprocessing is the foundation of everything that follows in an LLM pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5de016",
   "metadata": {},
   "source": [
    "## 2. Tokenization with BPE\n",
    "\n",
    "Modern LLMs use subword tokenization. \n",
    "We apply GPT-2's Byte Pair Encoding (BPE) tokenizer using `tiktoken`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1402aab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 5145\n",
      "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138, 257, 7026, 15632, 438, 2016, 257, 922, 5891, 1576, 438]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = tokenizer.encode(raw_text)\n",
    "\n",
    "print(\"Number of tokens:\", len(token_ids))\n",
    "print(token_ids[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ee9d2",
   "metadata": {},
   "source": [
    "## Why Byte Pair Encoding (BPE) matters\n",
    "\n",
    "Basic tokenization splits words by spaces and punctuation. However, real LLMs use subword tokenization such as BPE.\n",
    "\n",
    "BPE allows:\n",
    "\n",
    "- Handling unknown words\n",
    "- Reducing vocabulary size\n",
    "- Capturing morphological patterns\n",
    "- Efficient representation of rare words\n",
    "\n",
    "Instead of storing every word, BPE decomposes words into frequent subword units. This makes the model more generalizable and memory efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e6b484",
   "metadata": {},
   "source": [
    "## 3. Preparing Data for Next-Token Prediction\n",
    "\n",
    "LLMs are trained to predict the next token given previous tokens.\n",
    "\n",
    "To create training examples, we slide a fixed-length window across the token sequence. Each window produces:\n",
    "\n",
    "- An input sequence\n",
    "- A target sequence shifted by one position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b885174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 5141\n",
      "([40, 367, 2885, 1464], [367, 2885, 1464, 1807])\n"
     ]
    }
   ],
   "source": [
    "max_length = 4\n",
    "stride = 1\n",
    "\n",
    "samples = []\n",
    "\n",
    "for i in range(0, len(token_ids) - max_length, stride):\n",
    "    input_chunk = token_ids[i:i + max_length]\n",
    "    target_chunk = token_ids[i + 1:i + max_length + 1]\n",
    "    samples.append((input_chunk, target_chunk))\n",
    "\n",
    "print(\"Number of samples:\", len(samples))\n",
    "print(samples[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae68944",
   "metadata": {},
   "source": [
    "## Why sliding windows are used in LLM training\n",
    "\n",
    "LLMs are trained using next-token prediction. Instead of feeding the entire document at once, we generate multiple input-target pairs using a sliding window.\n",
    "\n",
    "This has three benefits:\n",
    "\n",
    "1. It increases the number of training samples.\n",
    "2. It preserves local contextual continuity.\n",
    "3. It allows fixed-length inputs for batch processing.\n",
    "\n",
    "Without overlapping windows, the model would see fewer context variations and generalize worse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d0d8c",
   "metadata": {},
   "source": [
    "## 4. Experiment: Effect of max_length and stride\n",
    "\n",
    "We evaluate how changing window size and stride impacts the number of generated training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd5123fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length=4, stride=1: 5141\n",
      "max_length=4, stride=4: 1286\n",
      "max_length=8, stride=1: 5137\n",
      "max_length=8, stride=8: 643\n"
     ]
    }
   ],
   "source": [
    "def count_samples(max_length, stride):\n",
    "    count = 0\n",
    "    for i in range(0, len(token_ids) - max_length, stride):\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "print(\"max_length=4, stride=1:\", count_samples(4,1))\n",
    "print(\"max_length=4, stride=4:\", count_samples(4,4))\n",
    "print(\"max_length=8, stride=1:\", count_samples(8,1))\n",
    "print(\"max_length=8, stride=8:\", count_samples(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f46bd5f",
   "metadata": {},
   "source": [
    "When stride = 1, the window moves one token at a time. This creates heavy overlap and therefore produces many training samples.\n",
    "\n",
    "When stride = max_length, there is no overlap. This drastically reduces the number of samples.\n",
    "\n",
    "Overlap is useful because:\n",
    "\n",
    "- It increases dataset size\n",
    "- It provides smoother context transitions\n",
    "- It improves statistical learning of next-token patterns\n",
    "\n",
    "However, too much overlap increases computational cost.\n",
    "\n",
    "Thus, stride is a tradeoff between efficiency and data richness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d1a7f5",
   "metadata": {},
   "source": [
    "## Why do embeddings encode meaning, and how are they related to neural networks?\n",
    "\n",
    "Embeddings encode meaning because they are learned representations optimized during training to minimize prediction error.\n",
    "\n",
    "In neural networks, embeddings are simply a lookup table (matrix) where:\n",
    "\n",
    "- Each token ID indexes a vector\n",
    "- The vector is updated via backpropagation\n",
    "\n",
    "Over time, tokens that appear in similar contexts develop similar vector representations. This reflects the distributional hypothesis: words used in similar contexts tend to have similar meanings.\n",
    "\n",
    "Thus, embeddings are not manually designed semantic vectors. They are emergent geometric structures learned through gradient descent.\n",
    "\n",
    "From a neural network perspective:\n",
    "\n",
    "- Embeddings are parameters\n",
    "- They are trained like any other weight\n",
    "- They form the first layer of the LLM\n",
    "\n",
    "This is why meaning in LLMs is geometric and relational rather than symbolic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cd7b11",
   "metadata": {},
   "source": [
    "## 5. Building a PyTorch Dataset\n",
    "\n",
    "To efficiently train neural networks, we structure the input-target pairs into a Dataset class.\n",
    "\n",
    "This allows:\n",
    "- Efficient batching\n",
    "- Shuffling\n",
    "- Parallel loading\n",
    "- Clean integration with PyTorch training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bd3cf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: torch.Size([2, 4])\n",
      "Targets shape: torch.Size([2, 4])\n",
      "\n",
      "Inputs:\n",
      "tensor([[  40,  367, 2885, 1464],\n",
      "        [ 367, 2885, 1464, 1807]])\n",
      "\n",
      "Targets:\n",
      "tensor([[ 367, 2885, 1464, 1807],\n",
      "        [2885, 1464, 1807, 3619]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, token_ids, max_length, stride):\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            self.inputs.append(torch.tensor(token_ids[i:i+max_length]))\n",
    "            self.targets.append(torch.tensor(token_ids[i+1:i+max_length+1]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "\n",
    "\n",
    "dataset = GPTDataset(token_ids, max_length=4, stride=1)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "inputs, targets = next(iter(dataloader))\n",
    "\n",
    "print(\"Inputs shape:\", inputs.shape)\n",
    "print(\"Targets shape:\", targets.shape)\n",
    "\n",
    "print(\"\\nInputs:\")\n",
    "print(inputs)\n",
    "\n",
    "print(\"\\nTargets:\")\n",
    "print(targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac7771",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we transformed raw text into structured training data suitable for Large Language Models.\n",
    "\n",
    "We implemented:\n",
    "- Modern subword tokenization (BPE)\n",
    "- Conversion to token IDs\n",
    "- Sliding window sampling\n",
    "- PyTorch Dataset creation\n",
    "\n",
    "We also experimentally analyzed how `max_length` and `stride` affect training sample generation.\n",
    "\n",
    "This process demonstrates that embeddings and training data construction are not arbitrary preprocessing steps â€” they define how meaning is represented, learned, and generalized in neural language models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
